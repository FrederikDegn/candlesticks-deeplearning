{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model Exploration - MobileNetv2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "### Package Setups\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "from tensorflow import keras\n",
    "import time\n",
    "\n",
    "from helperFunctions import *\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "#print all cell contents \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n"
   ]
  },
  {
   "source": [
    "* For training \n",
    "    + Use 50 files ~ 200K samples\n",
    "    + The shuffle buffer will be filled with 100K samples as 200K was resulting in memory overflow (Memory utilisation 25GB)\n",
    "* For Validation \n",
    "    + 5 files = 15K samples (~6%)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Configuation\n",
    "TRAIN_FILES_FOLDER = '../data/Train'\n",
    "VAL_FILES_FOLDER = '../data/Validation'\n",
    "TEST_FILES_FOLDER = '../data/Test'\n",
    "\n",
    "TRAIN_STEPS_PER_EPOCH_MULTIPLIER = 2\n",
    "VAL_STEPS_PER_EPOCH_MULTIPLIER = 2\n",
    "\n",
    "data_config = dict(INPUT_SHAPE = (128,128,3)\n",
    "                    ,TRAIN_FILES = 50\n",
    "                    ,TRAIN_BATCH_SIZE = 512\n",
    "                    ,VAL_FILES = 5\n",
    "                    ,VAL_BATCH_SIZE = 512\n",
    "                    ,PREFETCH = 5\n",
    "                  )\n",
    "\n",
    "###### buffer size reduced by half as memory overflow #########\n",
    "data_config.update(TRAIN_SHUFFLE_BUFFER_SIZE = 100000)\n",
    "# data_config.update(TRAIN_SHUFFLE_BUFFER_SIZE = samplesCount(data_config['TRAIN_FILES'],TRAIN_FILES_FOLDER))\n",
    "\n",
    "data_config.update(TRAIN_STEPS_PER_EPOCH = round(data_config['TRAIN_SHUFFLE_BUFFER_SIZE']/data_config['TRAIN_BATCH_SIZE'])*TRAIN_STEPS_PER_EPOCH_MULTIPLIER)\n",
    "\n",
    "data_config.update(VAL_SHUFFLE_BUFFER_SIZE = samplesCount(data_config['VAL_FILES'],VAL_FILES_FOLDER))\n",
    "data_config.update(VAL_STEPS_PER_EPOCH = round(data_config['VAL_SHUFFLE_BUFFER_SIZE']/data_config['VAL_BATCH_SIZE'])*VAL_STEPS_PER_EPOCH_MULTIPLIER)\n",
    "     \n",
    "# samplesCount(data_config['TRAIN_FILES'],TRAIN_FILES_FOLDER)\n",
    "# samplesCount(data_config['VAL_FILES'],VAL_FILES_FOLDER)\n",
    "\n",
    "\n",
    "### Model Configuration\n",
    "model_config = dict(\n",
    "      EXPERIMENT = 'Mobilenetv2 Baseline'\n",
    "      ,METRICS = [ keras.metrics.Precision(name='precision'),keras.metrics.Recall(name='recall'),keras.metrics.AUC(name='auc')]\n",
    "      ,LR = 1e-6\n",
    "      ,EPOCHS = 1000\n",
    "      ,VAL_FREQUENCY = 1\n",
    ")\n",
    "\n",
    "### Data Loading\n",
    "train = createIODataset(data_config['TRAIN_FILES'],TRAIN_FILES_FOLDER)\n",
    "val = createIODataset(data_config['VAL_FILES'],VAL_FILES_FOLDER)\n",
    "\n",
    "train = train.shuffle(buffer_size=data_config['TRAIN_SHUFFLE_BUFFER_SIZE'],reshuffle_each_iteration=True)\n",
    "train = train.repeat(-1)\n",
    "train = train.batch(data_config['TRAIN_BATCH_SIZE'],drop_remainder=True)\n",
    "train = train.prefetch(data_config['PREFETCH'])\n",
    "\n",
    "val = val.shuffle(buffer_size=data_config['VAL_SHUFFLE_BUFFER_SIZE'],reshuffle_each_iteration=True)\n",
    "val = val.repeat(-1)\n",
    "val = val.batch(data_config['VAL_BATCH_SIZE'],drop_remainder=True)\n",
    "val = val.prefetch(data_config['PREFETCH'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Mobilenetv2 Architecture"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(512, 4, 4, 1280)\n",
      "Number of layers in the base model:  155\n",
      "(512, 1280)\n",
      "(512, 1)\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_RealDiv (TensorF [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowO [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_128 (Functi (None, 4, 4, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1281      \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 1,863,873\n",
      "Non-trainable params: 395,392\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_config.update(FINE_TUNE_AT = 100)\n",
    "model_config.update(DROPOUT = 0.3)\n",
    "\n",
    "#MobileNetV2 expects pixel vaues in [-1,1]\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=data_config['INPUT_SHAPE'],include_top=False,weights='imagenet')\n",
    "\n",
    "#This feature extractor converts each 128x128x3 image into a 5x5x1280 block of features. \n",
    "# Let's see what it does to an example batch of images. (Batch size being 256)\n",
    "image_batch, label_batch = next(iter(train))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)\n",
    "\n",
    "# unfreeze the base_model and set the bottom layers to be un-trainable\n",
    "base_model.trainable = True\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = model_config['FINE_TUNE_AT']\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "  \n",
    "\n",
    "# Add a classification head\n",
    "# To generate predictions from the block of features, average over the spatial 5x5 spatial locations, \n",
    "# using a tf.keras.layers.GlobalAveragePooling2D layer to convert the features to a single 1280-element vector per image.\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)\n",
    "\n",
    "# Apply a tf.keras.layers.Dense layer to convert these features into a single prediction per image. \n",
    "prediction_layer = tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n",
    "\n",
    "# Build a model by chaining together the rescaling, base_model and feature extractor \n",
    "# layers using the Keras Functional API. As previously mentioned, use training=False as our \n",
    "# model contains a BatchNormalization layer.\n",
    "\n",
    "inputs = tf.keras.Input(shape=data_config['INPUT_SHAPE'])\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(model_config['DROPOUT'])(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"candlestick-CNN\", name = model_config['EXPERIMENT'] ,reinit= True,dir = '../data/'\n",
    "                    ,config = {**data_config,**model_config})\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=model_config['LR'])\n",
    "                        ,loss=tf.keras.losses.binary_crossentropy\n",
    "                        ,metrics=model_config['METRICS'])\n",
    "\n",
    "\n",
    "history = model.fit(train\n",
    "                ,epochs=model_config['EPOCHS']\n",
    "                ,steps_per_epoch=data_config['TRAIN_STEPS_PER_EPOCH']\n",
    "                ,verbose=1\n",
    "                ,validation_data=val                \n",
    "                ,validation_freq = model_config['VAL_FREQUENCY']\n",
    "                ,validation_steps = data_config['VAL_STEPS_PER_EPOCH']\n",
    "                ,callbacks=[WandbCallback()]\n",
    "                # ,ckpt_callback]\n",
    "                )\n",
    "  \n",
    "run.finish()\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "![CNN-Baseline-losses](./screenshots/20201117_mobilenet_dropout0.3_losses.png)\n",
    "\n",
    "## Observations\n",
    "* Model taking long time to converge\n",
    "* Overfits"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}